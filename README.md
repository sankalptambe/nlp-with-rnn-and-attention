# Natural Language Processing with RNNs and Attention
Exploring character RNN, stateless RNN, stateful RNN, RNN for sentimental analysis, Encoder-Decoder architecture and finally Transformer.

## Contents
* Building Shakespearean Text using a Character RNN
* Sentimental Analysis
* An Encoder-Decoder n/w for Neural Machine Translation
* The Transformer Architecture

## Sources
1. [Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
2. [ageron/handson-ml2](https://github.com/ageron/handson-ml2)
